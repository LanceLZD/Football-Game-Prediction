{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Importing required libraries\n",
    "import sqlite3\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer\n",
    "from time import time\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print (\"Reading data...\")\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "featureName = []\n",
    "#file = open(\"washed_data.csv\")\n",
    "file = open(\"washed_data2.csv\")\n",
    "for l in csv.reader(file):\n",
    "    data.append(l[1:-1])\n",
    "    labels.append(l[-1])\n",
    "featureName = data[0]\n",
    "del data[0]\n",
    "del labels[0]\n",
    "\n",
    "print (\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['home_team_goals_difference',\n",
       " 'away_team_goals_difference',\n",
       " 'games_won_home_team',\n",
       " 'games_won_away_team',\n",
       " 'games_against_won',\n",
       " 'games_against_lost',\n",
       " 'match_time_difference',\n",
       " 'last_matches_points_home',\n",
       " 'last_matches_points_away',\n",
       " 'League_1.0',\n",
       " 'League_1729.0',\n",
       " 'League_4769.0',\n",
       " 'League_7809.0',\n",
       " 'League_10257.0',\n",
       " 'League_13274.0',\n",
       " 'League_15722.0',\n",
       " 'League_17642.0',\n",
       " 'League_19694.0',\n",
       " 'League_21518.0',\n",
       " 'League_24558.0',\n",
       " 'home_player_1_overall_rating',\n",
       " 'home_player_2_overall_rating',\n",
       " 'home_player_3_overall_rating',\n",
       " 'home_player_4_overall_rating',\n",
       " 'home_player_5_overall_rating',\n",
       " 'home_player_6_overall_rating',\n",
       " 'home_player_7_overall_rating',\n",
       " 'home_player_8_overall_rating',\n",
       " 'home_player_9_overall_rating',\n",
       " 'home_player_10_overall_rating',\n",
       " 'home_player_11_overall_rating',\n",
       " 'away_player_1_overall_rating',\n",
       " 'away_player_2_overall_rating',\n",
       " 'away_player_3_overall_rating',\n",
       " 'away_player_4_overall_rating',\n",
       " 'away_player_5_overall_rating',\n",
       " 'away_player_6_overall_rating',\n",
       " 'away_player_7_overall_rating',\n",
       " 'away_player_8_overall_rating',\n",
       " 'away_player_9_overall_rating',\n",
       " 'away_player_10_overall_rating',\n",
       " 'away_player_11_overall_rating',\n",
       " 'home_team_api_id_buildUpPlaySpeed',\n",
       " 'home_team_api_id_buildUpPlayPassing',\n",
       " 'home_team_api_id_chanceCreationPassing',\n",
       " 'home_team_api_id_chanceCreationCrossing',\n",
       " 'home_team_api_id_chanceCreationShooting',\n",
       " 'home_team_api_id_defencePressure',\n",
       " 'home_team_api_id_defenceAggression',\n",
       " 'home_team_api_id_defenceTeamWidth',\n",
       " 'B365_Win',\n",
       " 'B365_Draw',\n",
       " 'B365_Defeat',\n",
       " 'BW_Win',\n",
       " 'BW_Draw',\n",
       " 'BW_Defeat']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### pre-process on X and y\n",
    "dataWash = []\n",
    "labelsNew = []\n",
    "for i in range(len(data)):\n",
    "    add = 1\n",
    "    timeDif = float(data[i][6])\n",
    "    data[i][6]=timeDif/3600/24\n",
    "    \n",
    "    for j in range(len(data[i])):\n",
    "        data[i][j] = float(data[i][j])\n",
    "    dataWash.append(data[i])\n",
    "    labelsNew.append(labels[i])\n",
    "data = dataWash\n",
    "labels = labelsNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### split train, validation, test data\n",
    "trainX = []\n",
    "trainy = []\n",
    "validateX = []\n",
    "validatey = []\n",
    "testX = []\n",
    "testy = []\n",
    "for i in range (len(data)):\n",
    "    rdm = np.random.random()\n",
    "    if rdm<0.6:\n",
    "        trainX.append(data[i])\n",
    "        trainy.append(labels[i])\n",
    "    elif rdm<0.8:\n",
    "        validateX.append(data[i])\n",
    "        validatey.append(labels[i])\n",
    "    else:\n",
    "        testX.append(data[i])\n",
    "        testy.append(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###  calculate accuracy\n",
    "def getAcc(predicty, testy):\n",
    "    correctCnt = 0\n",
    "    for i in range(len(testy)):\n",
    "        if predicty[i] == testy[i]:\n",
    "            correctCnt += 1\n",
    "    return correctCnt*1.0/len(testy)\n",
    "\n",
    "def getAccByLeague(predicty, testy, testX):\n",
    "    matchNumByLeague = [0]*11\n",
    "    correctByLeague = [0]*11\n",
    "    testMatchNum = len(predicty)\n",
    "    for i in range(testMatchNum):\n",
    "        label = testy[i]\n",
    "        pred = predicty[i]\n",
    "        for j in range(7,18,1):\n",
    "            if int(testX[i][j])==1:\n",
    "                matchNumByLeague[j-7]+=1\n",
    "                if label==pred:\n",
    "                    correctByLeague[j-7] += 1\n",
    "    accuracyByLeague = []\n",
    "    for i in range(11):\n",
    "        if matchNumByLeague[i]==0:\n",
    "            accuracyByLeague.append(0)\n",
    "        else:\n",
    "            accuracyByLeague.append(correctByLeague[i]*1.0/matchNumByLeague[i])\n",
    "    return accuracyByLeague"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of baseline is 0.45911096029860876\n"
     ]
    }
   ],
   "source": [
    "###  baseline: predict every match as home team wins\n",
    "predicty = ['Win']*len(testy)\n",
    "acc = getAcc(predicty,testy)\n",
    "print (\"accuracy of baseline is \"+str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of LR is 0.497115710892433\n",
      "[0.4654427645788337, 0.49427168576104746, 0.49444444444444446, 0.491566265060241, 0.4953051643192488, 0.4550408719346049, 0.4804177545691906, 0.5290697674418605, 0, 0.5638297872340425, 0.47368421052631576]\n"
     ]
    }
   ],
   "source": [
    "###   try logistic regression\n",
    "logClf = linear_model.LogisticRegression(multi_class = \"ovr\", solver = \"sag\", class_weight = 'balanced')\n",
    "logClf.fit(trainX,trainy)\n",
    "predicty = logClf.predict(testX)\n",
    "acc = getAcc(predicty,testy)\n",
    "print (\"accuracy of LR is \"+str(acc))\n",
    "\n",
    "accByLeague = getAccByLeague(predicty,testy,testX)\n",
    "print(accByLeague)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of LR is 0.4872751951136749\n",
      "[0.46220302375809935, 0.48226950354609927, 0.4666666666666667, 0.5108433734939759, 0.4507042253521127, 0.4550408719346049, 0.5117493472584856, 0.4883720930232558, 0, 0.5106382978723404, 0.47368421052631576]\n"
     ]
    }
   ],
   "source": [
    "###  only use lottery features\n",
    "trainXNew = []\n",
    "testXNew = []\n",
    "for row in trainX:\n",
    "    trainXNew.append(row[-6:])\n",
    "for row in testX:\n",
    "    testXNew.append(row[-6:])\n",
    "logClf = linear_model.LogisticRegression(multi_class = \"ovr\", solver = \"sag\", class_weight = 'balanced')\n",
    "logClf.fit(trainXNew,trainy)\n",
    "predicty = logClf.predict(testXNew)\n",
    "acc = getAcc(predicty,testy)\n",
    "print (\"accuracy of LR is \"+str(acc))\n",
    "accByLeague = getAccByLeague(predicty,testy,testX)\n",
    "print(accByLeague)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of GNB is 0.4825246012894469\n",
      "[0.4524838012958963, 0.4735406437534097, 0.4666666666666667, 0.5253012048192771, 0.4131455399061033, 0.4359673024523161, 0.46736292428198434, 0.4941860465116279, 0, 0.5106382978723404, 0.5307017543859649]\n"
     ]
    }
   ],
   "source": [
    "###  try gaussian naive bayes\n",
    "GNBClf = GaussianNB()\n",
    "GNBClf.fit(trainX,trainy)\n",
    "predicty = GNBClf.predict(testX)\n",
    "acc = getAcc(predicty,testy)\n",
    "print (\"accuracy of GNB is \"+str(acc))\n",
    "\n",
    "accByLeague = getAccByLeague(predicty,testy,testX)\n",
    "print(accByLeague)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of RF is 0.5256192738378012\n",
      "[0.5005399568034558, 0.5231860338243317, 0.49444444444444446, 0.5397590361445783, 0.48826291079812206, 0.47956403269754766, 0.5274151436031331, 0.5406976744186046, 0, 0.5638297872340425, 0.5307017543859649]\n"
     ]
    }
   ],
   "source": [
    "###  try random forest\n",
    "RFClf = RandomForestClassifier(n_estimators = 200, random_state = 1, class_weight = 'balanced')\n",
    "RFClf.fit(trainX,trainy)\n",
    "predicty = RFClf.predict(testX)\n",
    "acc = getAcc(predicty,testy)\n",
    "print (\"accuracy of RF is \"+str(acc))\n",
    "\n",
    "accByLeague = getAccByLeague(predicty,testy,testX)\n",
    "print(accByLeague)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of AB is 0.499151679674245\n",
      "[0.46490280777537796, 0.4909983633387889, 0.45555555555555555, 0.4891566265060241, 0.44366197183098594, 0.46321525885558584, 0.5143603133159269, 0.5261627906976745, 0, 0.5797872340425532, 0.5087719298245614]\n"
     ]
    }
   ],
   "source": [
    "###  try adaboost\n",
    "ABClf = AdaBoostClassifier(n_estimators = 200, random_state = 2)\n",
    "ABClf.fit(trainX,trainy)\n",
    "predicty = ABClf.predict(testX)\n",
    "acc = getAcc(predicty,testy)\n",
    "print (\"accuracy of AB is \"+str(acc))\n",
    "\n",
    "accByLeague = getAccByLeague(predicty,testy,testX)\n",
    "print(accByLeague)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of KNN is 0.44044791313199866\n",
      "[0.4136069114470842, 0.4402618657937807, 0.4222222222222222, 0.46265060240963857, 0.4154929577464789, 0.3869209809264305, 0.4046997389033943, 0.4622093023255814, 0, 0.526595744680851, 0.4517543859649123]\n"
     ]
    }
   ],
   "source": [
    "###  try KNN\n",
    "KNNClf =  KNeighborsClassifier()\n",
    "KNNClf.fit(trainX,trainy)\n",
    "predicty = KNNClf.predict(testX)\n",
    "acc = getAcc(predicty,testy)\n",
    "print (\"accuracy of KNN is \"+str(acc))\n",
    "\n",
    "accByLeague = getAccByLeague(predicty,testy,testX)\n",
    "print(accByLeague)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
